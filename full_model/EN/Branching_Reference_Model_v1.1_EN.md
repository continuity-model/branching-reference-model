
# Branching Reference Model v1.1
## — A Structure for Reference, Not for Memory —

---

## 1. The Core Problem

Current LLMs treat memory as a single continuous context.
This “linear context model” creates major failures in human–AI collaboration:

- Weak handling of ambiguous references (“that”, “the earlier one”)
- Context mixing leading to decision drift
- AI selecting plausible but incorrect interpretations

As a result, users experience unstable conversations where shared reference does not truly exist.

---

## 2. The Fundamental Misconception

A common assumption in AI memory design is:

> The more memory an AI stores and retrieves efficiently, the smarter it becomes.

In reality, the core problem is not memory quantity.

---

## 3. The Real Issue

Memory is not a storage problem. It is a reference problem.

In collaboration, what matters is not how much is remembered,
but whether both parties can reliably identify which memory is being referenced.

---

## 4. Definition

The Branching Reference Model is:

A structure that stabilizes human–AI collaboration by intentionally placing referenceable branches instead of integrating memory into a single narrative.

AI does not need to replicate human memory.
It only needs to provide navigable reference branches.

---

## 5. Core Structure

### Absolute Rule Layer
The highest, non-negotiable memory domain.
Contains priorities, goals, constraints, and values.
This layer must never be compressed or relativized.

### Branching Memory Layers
Different types of memory remain separated:

- Facts — Objective events
- Decisions — Confirmed agreements
- State — Current situation
- Relations — Collaboration context
- Generated — AI outputs (isolated from facts)

### Reference Tags
Tags function as reference pointers, not classification labels.

### Reference Navigation
When ambiguity occurs:
1. AI proposes candidate branches
2. User confirms the intended reference
3. Reasoning proceeds afterward

---

## 6. Branching Principles

1. Facts must never be integrated into a single narrative
2. Generated content must remain isolated from factual memory
3. Memory exists to provide referencability, not accumulation

---

## 7. Referential Continuity

Continuity does not come from deep contextual history.
Continuity comes from navigability.

This enables:

- Stability independent of memory size
- Shallow active context during reasoning
- On‑demand deep retrieval only when needed

This property is called:

Referential Continuity — stable interaction maintained through reliable reference rather than deep context preservation.

---

## 8. Implementation Keys

### Tag Alignment
Tags must align with user intuition.
Systems must allow user correction of reference pointers.

### Absolute Rule Stability
The rule layer must be treated as an immutable memory domain.

---

## 9. Conclusion

The Branching Reference Model is not a memory organization technique.

It is:

A protocol for structuring trust between humans and AI.

---

## 10. Core Statement

The purpose of memory is not retention.
The purpose of memory is referencability.
