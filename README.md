ğŸŒ **Language / è¨€èª**
- ğŸ‡ºğŸ‡¸ English (current)
- ğŸ‡¯ğŸ‡µ [æ—¥æœ¬èªç‰ˆã¯ã“ã¡ã‚‰](README_jp.md)

# Branching Reference Model (BRM)

![Linear vs BRM](docs/img/linear_vs_brm_v2.png)

A structural framework for stabilizing long-term AI collaboration.

---

## Why AI Collaboration Breaks

Long conversations appear stable.

Beneath the surface:
- Meaning drifts  
- Anchors dissolve  
- Context collapses  
- Internal bias accumulates  

This is not an intelligence failure.  
It is a structural continuity problem.

---

## Structural Evolution of Internal Control

| Aspect | Role Prompting | Context Accumulation | Anchoring | BRM |
|--------|---------------|---------------------|-----------|------|
| Long-term stability | Low | Medium | High | **Very High** |
| Drift resistance | Low | Medium | High | **Structural** |
| Rule persistence | Low | Medium | **High** | **Very High** |
| Role fixation | Temporary | Context-dependent | **Stable** | **Structural + Recoverable** |
| Recoverability | No | Limited | Partial | **Yes** |
| Structural visibility | Hidden | Hidden | Semi-explicit | **Explicit** |

- **Role Prompting**: Behavioral instruction at initialization.
- **Context Accumulation**: Stability through memory stacking.
- **Anchoring**: Structural control of internal reference priority.
- **BRM**: Explicit scoping architecture with recoverable reference slots.

---

## Before the Model â€” Anchoring Theory

Prompts dissolve.

What governs AI output is not the first command â€” but the strongest internal reference field formed during interaction.

- [Anchoring Theory â€” Dissolving Prompts and the Permanent Anchor (EN)](core/EN/Anchoring_Theory_Dissolving_Prompts_EN.md)
- [ã‚¢ãƒ³ã‚«ãƒ¼ãƒªãƒ³ã‚°ç†è«– â€” æº¶ã‘ã‚‹å…¥æµ´å‰¤ã¨ã€æº¶ã‘ãªã„ç¢‡ (JP)](core/JP/Anchoring_Theory_Dissolving_Prompts_JP.md)

---

## The Foundation

- [The Structural Gap in Long-Term LLM Collaboration (EN)](core/EN/Structural_Gap_in_Long_Term_LLM_Collaboration.md)
- [The Structural Gap in Long-Term LLM Collaboration (JP)](core/JP/Structural_Gap_in_Long_Term_LLM_Collaboration_JP.md)

---

## Core Model

- [Core Definition (EN)](core/EN/BRM_Core_Definition_EN.md)
- [Core Definition (JP)](core/JP/BRM_Core_Definition_JP.md)

---

## Capability Expansion (Separate Axis)

BRM does not compete with RAG or extended context windows.

Those approaches expand **capacity**.  
BRM stabilizes **reference scope**.

These are different architectural variables.

---

## Full Structured Model

- [Full Model (EN)](full_model/EN/)
- [Full Model (JP)](full_model/JP/)

---

## Final Thought

AI collapse is not chaos.

It is gravity without design.

The industry keeps expanding context windows.  
Without structural anchors, we are only expanding the ocean.
